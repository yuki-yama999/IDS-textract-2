import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
import PyPDF2
import io
import openai
from anthropic import Anthropic
from google.ai import generativelanguage as glm
from google.api_core import client_options

# Load environment variables from .env file
load_dotenv()

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å®šç¾©
PROMPT_TEMPLATES = {
    "è¦ç´„": "ä»¥ä¸‹ã®æ–‡æ›¸ã‚’è¦ç´„ã—ã¦ãã ã•ã„:\n{document}",
    "é‡è¦ãªãƒã‚¤ãƒ³ãƒˆæŠ½å‡º": "ä»¥ä¸‹ã®æ–‡æ›¸ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§æŠ½å‡ºã—ã¦ãã ã•ã„:\n{document}",
    "è²¡å‹™åˆ†æ": "ä»¥ä¸‹ã®æ–‡æ›¸ã‹ã‚‰è²¡å‹™ã«é–¢ã™ã‚‹é‡è¦ãªæƒ…å ±ã‚’åˆ†æã—ã¦ãã ã•ã„:\n{document}",
    "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "ä»¥ä¸‹ã®æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n{document}\n\nè³ªå•: {question}"
}

# Show title and description.
st.title("ğŸ“„ Financial Document Exstractor")
st.write(
    "Upload a document below and ask a question about it."
)

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
model_option = st.selectbox(
    "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["Gemini-1.5-pro", "gpt-4o", "Claude-3-sonnet"],
    index=0
)

# APIã‚­ãƒ¼å…¥åŠ›
if model_option == "Gemini-1.5-pro":
    api_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-pro')
elif model_option == "gpt-4o":
    api_key = st.text_input("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    openai.api_key = api_key
elif model_option == "Claude-3-sonnet":
    api_key = st.text_input("Anthropic APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("Anthropic APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    anthropic = Anthropic(api_key=api_key)

# Let the user upload a file via `st.file_uploader`.
uploaded_file = st.file_uploader(
    "Upload a document (.txt, .md, or .pdf)", type=("txt", "md", "pdf")
)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠ
template_name = st.selectbox(
    "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=list(PROMPT_TEMPLATES.keys()),
    disabled=not uploaded_file
)

# ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã®å…¥åŠ›æ¬„ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒ"ã‚«ã‚¹ã‚¿ãƒ è³ªå•"ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
question = ""
if template_name == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•":
    question = st.text_area(
        "æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        disabled=not uploaded_file,
    )

# é€ä¿¡ãƒœã‚¿ãƒ³ã®è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿æœ‰åŠ¹åŒ–ï¼‰
submit_button = st.button("åˆ†æé–‹å§‹", disabled=not uploaded_file)

if submit_button and uploaded_file:
    # ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã®å ´åˆã¯è³ªå•ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if template_name == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•" and not question:
        st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        try:
            # Process the uploaded file based on its type
            if uploaded_file.type == "application/pdf":
                # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
                document = ""
                for page in pdf_reader.pages:
                    document += page.extract_text() + "\n"
            else:
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                document = uploaded_file.read().decode()
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            prompt = PROMPT_TEMPLATES[template_name].format(
                document=document,
                question=question
            )

            # Generate an answer based on selected model
            if model_option == "Gemini-1.5-pro":
                response = model.generate_content(prompt, stream=True)
                for chunk in response:
                    st.write(chunk.text)
            elif model_option == "gpt-4o":
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                for chunk in response:
                    if "content" in chunk.choices[0].delta:
                        st.write(chunk.choices[0].delta.content)
            else:  # Claude-3-sonnet
                message = anthropic.messages.create(
                    model="claude-3-sonnet",
                    max_tokens=1000,
                    messages=[{"role": "user", "content": prompt}]
                )
                st.write(message.content)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
