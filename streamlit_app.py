import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
import PyPDF2
import io
import openai
from anthropic import Anthropic
from google.ai import generativelanguage as glm
from google.api_core import client_options

# Load environment variables from .env file
load_dotenv()

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å®šç¾©
PROMPT_TEMPLATES = {
    "è¦ç´„": "ä»¥ä¸‹ã®æ–‡æ›¸ã‚’è¦ç´„ã—ã¦ãã ã•ã„:\n{document}",
    "é‡è¦ãªãƒã‚¤ãƒ³ãƒˆæŠ½å‡º": "ä»¥ä¸‹ã®æ–‡æ›¸ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§æŠ½å‡ºã—ã¦ãã ã•ã„:\n{document}",
    "å›½å†…å‚µåˆ¸ å…¬å‹Ÿä¸Šå ´ãƒ»éä¸Šå ´æ™®é€šå‚µåˆ¸å±æ€§": """å…¥åŠ›ã•ã‚ŒãŸå›½å†…å‚µåˆ¸ã«é–¢ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿å–ã‚Šã€ä»¥ä¸‹ã®é …ç›®ã«å¯¾ã™ã‚‹æƒ…å ±ã‚’æŠ½å‡ºã—ã¦è¡¨å½¢å¼ã§æ•™ãˆã¦ãã ã•ã„ã€‚
ãªãŠã€è¡¨å½¢å¼ã¯ã€é …ç›®ã€å†…å®¹ã€æ ¹æ‹ ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
æ ¹æ‹ ã«ã¯ã€å¼•ç”¨ç®‡æ‰€ã®è©²å½“ãƒšãƒ¼ã‚¸æ•°ã¨å…ƒã®æ–‡ç« ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

#æŠ½å‡ºã—ãŸã„é …ç›®
ãƒ»å„Ÿé‚„æ—¥ï¼ˆYYYYMMDDå½¢å¼ã§ï¼‰
ãƒ»éŠ˜æŸ„åç§°
ãƒ»å‹Ÿé›†æ–¹å¼åŒºåˆ†ï¼ˆå…¬å‹Ÿå‚µãªã‚‰ï¼‘ã€€éå…¬å‹Ÿå‚µãªã‚‰ï¼’ï¼‰
ãƒ»åˆ©æ‰•æ—¥ï¼‘ï¼ˆMMDDå½¢å¼ã€€è¤‡æ•°ã‚ã‚‹å ´åˆã¯æ¬¡ã®é …ç›®ã«è¨˜è¼‰ï¼‰
ãƒ»åˆ©æ‰•æ—¥ï¼’ï¼ˆMMDDå½¢å¼ï¼‰
ãƒ»åˆ©æ‰•æ—¥ï¼“ï¼ˆMMDDå½¢å¼ï¼‰
ãƒ»åˆ©æ‰•æ—¥ï¼”ï¼ˆMMDDå½¢å¼ï¼‰
ãƒ»å•†å“ç¨®åˆ¥ï¼ˆä¸‹è¨˜ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã—ã¦ï¼‰
A0 ï¼š å‰²å¼•çŸ­æœŸå›½å‚µç­‰
A1 ï¼š åˆ©ä»˜å›½å‚µ
A2 ï¼š å‰²å¼•å›½å‚µ
B0 ï¼š åœ°æ–¹å‚µ
C0 ï¼š æ”¿åºœä¿è¨¼å‚µãƒ»éæ”¿åºœä¿è¨¼å‚µ
E0 ï¼š ç‰¹æ®Šå‚µ(æ±äº¬äº¤é€šå‚µåˆ¸ãƒ»æ”¾é€å‚µåˆ¸)
F0 ï¼š åˆ©ä»˜é›»ã€…å‚µ
G0 ï¼š å‰²å¼•é›»ã€…å‚µ
H0 ï¼š åˆ©ä»˜é‡‘èå‚µ
I1 ï¼š å‰²å¼•ã¿ãšã»éŠ€è¡Œå‚µåˆ¸
I2 ï¼š å‰²å¼•å•†å·¥å‚µåˆ¸
I3 ï¼š å‰²å¼•è¾²æ—å‚µåˆ¸
I4 ï¼š å‰²å¼•é•·æœŸä¿¡ç”¨å‚µåˆ¸
I5 ï¼š å‰²å¼•ã‚ãŠãã‚‰å‚µåˆ¸
I6 ï¼š å‰²å¼•æ±äº¬ä¸‰è±éŠ€è¡Œå‚µåˆ¸
J1ï½9 ï¼š äº‹æ¥­å‚µ
K1ï½9 ï¼š é›»åŠ›å‚µ
ZS ï¼š å††å»ºå¤–å‚µï¼ˆå›½å‚µï¼‰
ZT ï¼š å††å»ºå¤–å‚µï¼ˆåœ°æ–¹å‚µï¼‰
ZX ï¼š å††å»ºå¤–å‚µï¼ˆãã®ä»–å‚µï¼‰
ãƒ»åˆ©å‰²åŒºåˆ†ï¼ˆ1 ï¼š åˆ©ä»˜å‚µ 2 ï¼š å‰²å¼•å‚µï¼‰
ãƒ»åˆ©æ‰•æ–¹å¼åŒºåˆ†ï¼ˆ0 ï¼š å‰²å¼•å‚µ ã€€1 ï¼š å›ºå®šåˆ©ä»˜å‚µã€€ 2 ï¼š å¤‰å‹•åˆ©ä»˜å‚µ ã€€3 ï¼š ã‚¹ãƒ†ãƒƒãƒ—å‚µï¼‰
\n{document}""",
    "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "ä»¥ä¸‹ã®æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n{document}\n\nè³ªå•: {question}"
}

# Show title and description.
st.title("ğŸ“„ Financial Document Exstractor")
st.write(
    "Upload a document below and ask a question about it."
)

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
model_option = st.selectbox(
    "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["Gemini-1.5-pro", "gpt-4o", "Claude-3-sonnet"],
    index=0
)

# APIã‚­ãƒ¼å…¥åŠ›
if model_option == "Gemini-1.5-pro":
    api_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-pro')
elif model_option == "gpt-4o":
    api_key = st.text_input("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    openai.api_key = api_key
elif model_option == "Claude-3-sonnet":
    api_key = st.text_input("Anthropic APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if not api_key:
        st.error("Anthropic APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
        st.stop()
    anthropic = Anthropic(api_key=api_key)

# Let the user upload a file via `st.file_uploader`.
uploaded_file = st.file_uploader(
    "Upload a document (.txt, .md, or .pdf)", type=("txt", "md", "pdf")
)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠ
template_name = st.selectbox(
    "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=list(PROMPT_TEMPLATES.keys()),
    disabled=not uploaded_file
)

# ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã®å…¥åŠ›æ¬„ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒ"ã‚«ã‚¹ã‚¿ãƒ è³ªå•"ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
question = ""
if template_name == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•":
    question = st.text_area(
        "æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        disabled=not uploaded_file,
    )

# é€ä¿¡ãƒœã‚¿ãƒ³ã®è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿æœ‰åŠ¹åŒ–ï¼‰
submit_button = st.button("åˆ†æé–‹å§‹", disabled=not uploaded_file)

if submit_button and uploaded_file:
    # ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã®å ´åˆã¯è³ªå•ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if template_name == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•" and not question:
        st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        try:
            # Process the uploaded file based on its type
            if uploaded_file.type == "application/pdf":
                # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
                document = ""
                for page in pdf_reader.pages:
                    document += page.extract_text() + "\n"
            else:
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                document = uploaded_file.read().decode()
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
            prompt = PROMPT_TEMPLATES[template_name].format(
                document=document,
                question=question
            )

            # Generate an answer based on selected model
            if model_option == "Gemini-1.5-pro":
                response = model.generate_content(prompt, stream=True)
                for chunk in response:
                    st.write(chunk.text)
            elif model_option == "gpt-4o":
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                for chunk in response:
                    if "content" in chunk.choices[0].delta:
                        st.write(chunk.choices[0].delta.content)
            else:  # Claude-3-sonnet
                message = anthropic.messages.create(
                    model="claude-3-sonnet",
                    max_tokens=1000,
                    messages=[{"role": "user", "content": prompt}]
                )
                st.write(message.content)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
