import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å®šç¾©
PROMPT_TEMPLATES = {
    "è¦ç´„": "ä»¥ä¸‹ã®æ–‡æ›¸ã‚’è¦ç´„ã—ã¦ãã ã•ã„:\n{document}",
    "é‡è¦ãªãƒã‚¤ãƒ³ãƒˆæŠ½å‡º": "ä»¥ä¸‹ã®æ–‡æ›¸ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§æŠ½å‡ºã—ã¦ãã ã•ã„:\n{document}",
    "è²¡å‹™åˆ†æ": "ä»¥ä¸‹ã®æ–‡æ›¸ã‹ã‚‰è²¡å‹™ã«é–¢ã™ã‚‹é‡è¦ãªæƒ…å ±ã‚’åˆ†æã—ã¦ãã ã•ã„:\n{document}",
    "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "ä»¥ä¸‹ã®æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n{document}\n\nè³ªå•: {question}"
}

# Show title and description.
st.title("ğŸ“„ Financial Document Exstractor")
st.write(
    "Upload a document below and ask a question about it."
)

# Get API key from user input
gemini_api_key = st.text_input("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
if not gemini_api_key:
    st.error("Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", icon="ğŸš¨")
    st.stop()

# Configure Gemini API
genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel('gemini-pro')

# Let the user upload a file via `st.file_uploader`.
uploaded_file = st.file_uploader(
    "Upload a document (.txt or .md)", type=("txt", "md")
)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é¸æŠ
template_name = st.selectbox(
    "åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=list(PROMPT_TEMPLATES.keys()),
    disabled=not uploaded_file
)

# ã‚«ã‚¹ã‚¿ãƒ è³ªå•ã®å…¥åŠ›æ¬„ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒ"ã‚«ã‚¹ã‚¿ãƒ è³ªå•"ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
question = ""
if template_name == "ã‚«ã‚¹ã‚¿ãƒ è³ªå•":
    question = st.text_area(
        "æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        disabled=not uploaded_file,
    )

if uploaded_file and (template_name != "ã‚«ã‚¹ã‚¿ãƒ è³ªå•" or question):
    # Process the uploaded file and question.
    document = uploaded_file.read().decode()
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    prompt = PROMPT_TEMPLATES[template_name].format(
        document=document,
        question=question
    )

    # Generate an answer using the Gemini API
    response = model.generate_content(prompt, stream=True)

    # Stream the response to the app
    for chunk in response:
        st.write(chunk.text)
